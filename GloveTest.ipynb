{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "64e69ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "# The first time you run this will download a ~823MB file\n",
    "glove = torchtext.vocab.GloVe(name=\"840B\", # trained on Wikipedia 2014 corpus\n",
    "                              dim=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "86de430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastdtw import fastdtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d53295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word has ViCo component\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "\n",
    "word = 'dog'\n",
    "\n",
    "glove_dim=300\n",
    "\n",
    "model_path = '.vector_cache/pretrained_vico/glove_300_vico_linear_200/'\n",
    "\n",
    "f = h5py.File(f'{model_path}/visual_word_vecs.h5py','r')\n",
    "word_to_idx = json.load(open(f'{model_path}/visual_word_vecs_idx.json','r'))\n",
    "visual_words = json.load(open(f'{model_path}/visual_words.json','r'))\n",
    "\n",
    "# To just slice the row in the matrix without loading the full matrix in RAM do the following:\n",
    "embed_mat = f['embeddings'][()]\n",
    "\n",
    "# To load the entire matrix in memory (recommended if you are going to query words frequently) use the following instead:\n",
    "# embed_mat = f[embeddings][()]\n",
    "\n",
    "if word in word_to_idx:\n",
    "    word_embed = embed_mat[word_to_idx[word]]\n",
    "    word_embed_glove = word_embed[:glove_dim] # GloVe component\n",
    "    word_embed_vico = word_embed[glove_dim:]  # ViCo component\n",
    "else:\n",
    "    print('Word not in vocabulary')\n",
    "\n",
    "if word in visual_words:\n",
    "    print('Word has ViCo component')\n",
    "else:\n",
    "    print('Word is not in the visual word vocabulary. word_embed_vico is set to average ViCo embedding computed across visual words')\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6ae570fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vico(word):\n",
    "    if word in word_to_idx:\n",
    "        word_embed = embed_mat[word_to_idx[word]]\n",
    "        _glove = torch.tensor(word_embed[:glove_dim]) # GloVe component\n",
    "        _vico = torch.tensor(word_embed[glove_dim:])  # ViCo component\n",
    "        return _vico\n",
    "    else:\n",
    "        print('I don\\'t know', word)\n",
    "        return torch.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a684d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "def DTW(seq_a, seq_b, band_width=3, fast=False):\n",
    "    \"\"\"\n",
    "    DTW is used to find the optimal alignment path;\n",
    "    Returns GT like 001110000 for each seq_a\n",
    "    \"\"\"\n",
    "    if fast:\n",
    "        if band_width is None:\n",
    "            path, dist = dtw_path_from_metric(seq_a.detach().cpu().numpy(),\n",
    "                                              seq_b.detach().cpu().numpy())\n",
    "        else:\n",
    "            path, dist = dtw_path_from_metric(seq_a.detach().cpu().numpy(),\n",
    "                                              seq_b.detach().cpu().numpy(),\n",
    "                                              sakoe_chiba_radius=band_width)\n",
    "    else:\n",
    "        if band_width is None:\n",
    "            dist, path = fastdtw(seq_a.detach().cpu().numpy(),\n",
    "                                              seq_b.detach().cpu().numpy())\n",
    "        else:\n",
    "            dist, path = fastdtw(seq_a.detach().cpu().numpy(),\n",
    "                                              seq_b.detach().cpu().numpy(),\n",
    "                                              radius=band_width)\n",
    "    ndtw = np.exp(-dist/(len(seq_b) + len(seq_a)))\n",
    "    return ndtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "839c9f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.1493)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.vstack([glove['laptop'], glove['table'], glove['ron']]).sum(0)\n",
    "y = torch.vstack([glove['laptop'], glove['bench'], glove['television'], glove['toy']]).sum(0)\n",
    "\n",
    "\n",
    "torch.norm(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ac4eb50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.786944621870715"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.vstack([vico('laptop'), vico('table'), vico('television')]).sum(0)\n",
    "y = torch.vstack([vico('laptop'), vico('bench'), vico('television'), vico('toy')]).sum(0)\n",
    "\n",
    "\n",
    "np.linalg.norm(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c0ae9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.2889)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.vstack([glove['laptop'], glove['table'], glove['tv']]).sum(0)\n",
    "y = torch.vstack([glove['laptop'], glove['bathroom'], glove['television'], ]).sum(0)\n",
    "\n",
    "x = torch.vstack([x, glove['tv']]).sum(0)\n",
    "torch.norm(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe679fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8372)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.vstack([glove['rob']]).sum(0)\n",
    "y = torch.vstack([glove['laptop'], glove['bench'], glove['television']]).sum(0)\n",
    "\n",
    "# x += glove['tv']\n",
    "torch.norm(y - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0b7c8432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010925987588726625\n",
      "0.0005696911484005163\n"
     ]
    }
   ],
   "source": [
    "# DTW\n",
    "loc1 = torch.stack([(glove['computer'] + glove['plant'] + glove['something'])/3 , (glove['toilet'] + glove['shower']) / 2, glove['tv']])\n",
    "loc2 = torch.stack([glove['plant'], glove['tv'] + glove['remote_controller']])\n",
    "\n",
    "\n",
    "path = torch.stack([glove['computer'], glove['bathroom'], glove['television']])\n",
    "print(DTW(loc1, path, 1))\n",
    "print(DTW(loc2, path, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8ed2a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know fireexinguisher\n",
      "I don't know washing machine\n",
      "I don't know fireexinguisher\n",
      "I don't know washing machine\n",
      "1a 1.3552296459938273e-05\n",
      "1b 7.046801227704599e-06\n",
      "12 0.0002028168750412643\n",
      "12c 0.0013251195469679026\n",
      "12d 0.0013428706298528902\n",
      "123e 0.002960929169360092\n",
      "1234 0.0019921283492005553\n",
      "1234f 0.01304474942397376\n",
      "1234g 0.08654474225307786\n",
      "1234g 0.0692357938024623\n",
      "1234h 0.11153828277854577\n",
      "12345 0.014956566376992986\n",
      "12345h 0.003617251522438981\n",
      "123456 0.04108958079684591\n"
     ]
    }
   ],
   "source": [
    "all_objects = torch.stack([vico('window'), vico('chair'), vico('plant'), \n",
    "                           vico('couch'), vico('fireexinguisher'), \n",
    "                           vico('stair'), vico('lamp'), vico('fireplace'), \n",
    "                           vico('bed'), vico('washing machine'), vico('sink'),vico('toilet')]).sum(0)\n",
    "\n",
    "# DTW\n",
    "bad_path1a = torch.stack([vico('window'), vico('chair')])\n",
    "bad_path1b = torch.stack([vico('window'), vico('plant')])\n",
    "bad_path12 = torch.stack([vico('window'), vico('couch')])\n",
    "bad_path12c = torch.stack([vico('window'), vico('couch'), vico('fireexinguisher')])\n",
    "bad_path12d = torch.stack([vico('window'), vico('couch'), vico('stair')])\n",
    "bad_path123e = torch.stack([vico('window'), vico('couch'), vico('picture')])\n",
    "bad_path123e = torch.stack([vico('window'), vico('couch'), vico('picture'), vico('lamp')])\n",
    "bad_path1234 = torch.stack([vico('window'), vico('couch') ,vico('picture'), vico('fireplace')])\n",
    "bad_path1234f = torch.stack([vico('window'), vico('couch'), vico('picture'), vico('fireplace'), vico('bed')])\n",
    "bad_path1234g = torch.stack([vico('window'), vico('couch'), vico('picture'), vico('fireplace'), vico('washing machine')])\n",
    "bad_path1234h = torch.stack([vico('window'), vico('couch'), vico('picture'), vico('fireplace'), vico('bathtub')])\n",
    "bad_path12345 = torch.stack([vico('window'), vico('couch') ,vico('picture'), vico('fireplace'), vico('sink')])\n",
    "bad_path12345h = torch.stack([vico('window'), vico('couch') ,vico('picture'), vico('fireplace'), vico('sink'), vico('bathtub')])\n",
    "\n",
    "bad_path123456 = torch.stack([vico('window'), vico('couch') ,vico('picture'), vico('fireplace'), vico('sink'), vico('toilet')])\n",
    "\n",
    "gt_path = torch.stack([vico('window'), vico('couch'), vico('fireplace'), vico('bathtub')])\n",
    "\n",
    "\n",
    "print('1a', DTW(bad_path1a, gt_path, fast=True) * 0.001)\n",
    "print('1b',DTW(bad_path1b, gt_path, fast=True) * 0.001)\n",
    "print('12', DTW(bad_path12, gt_path, fast=True) * 0.005)\n",
    "\n",
    "print('12c', DTW(bad_path12c, gt_path, fast=True) * 0.01)\n",
    "print('12d', DTW(bad_path12d, gt_path, fast=True) * 0.02)\n",
    "print('123e', DTW(bad_path123e, gt_path, fast=True) * 0.03)\n",
    "\n",
    "print('1234', DTW(bad_path1234, gt_path, fast=True) * 0.02)\n",
    "print('1234f', DTW(bad_path1234f, gt_path, fast=True) * 0.1)\n",
    "print('1234g', DTW(bad_path1234g, gt_path, fast=True) * 0.5)\n",
    "\n",
    "print('1234g', DTW(bad_path1234g, gt_path, fast=True) * 0.4)\n",
    "print('1234h', DTW(bad_path1234h, gt_path, fast=True) * 0.3)\n",
    "print('12345', DTW(bad_path12345, gt_path, fast=True) * 0.1)\n",
    "\n",
    "print('12345h', DTW(bad_path12345h, gt_path, fast=True) * 0.02)\n",
    "print('123456', DTW(bad_path123456, gt_path, fast=True) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1972b5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4718], dtype=torch.float64)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/torch.cosine_similarity((vico('bathtub')).unsqueeze(0), all_objects.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1c34febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4456], dtype=torch.float64)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/torch.cosine_similarity((vico('bathtub') + vico('shower')).unsqueeze(0), all_objects.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b170cd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/torch.cosine_similarity(all_objects.unsqueeze(0), all_objects.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6cd9c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vico('bathtub').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb7d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
